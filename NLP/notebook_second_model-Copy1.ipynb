{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795c6c59",
   "metadata": {},
   "source": [
    "## Contexte du projet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c92c23",
   "metadata": {},
   "source": [
    "Nous sommes chargés de créer un model IA capable de détecter les email SPAM, qu'elle puisse différencier ceux qui le sont avec ceux qui ne le sont pas, grâce au NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2753aa2b",
   "metadata": {},
   "source": [
    "## Information dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30908c52",
   "metadata": {},
   "source": [
    "Le dataset comporte 3 colonnes et 5796 lignes :  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c92527",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Category : Specifies whether mail is spam or not.  \n",
    "\n",
    "1 --> Spam  \n",
    "0 --> Not spam</li>  \n",
    "<li>Message : Raw text messages  \n",
    "Combinations of Plain messages with headers and also few with HTML tags.</li>  \n",
    "<li>File_Name: Unique message indicators</li>  \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf89d509",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1e3dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "#saving\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b803d8d",
   "metadata": {},
   "source": [
    "## Forme dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a648d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>FILE_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...</td>\n",
       "      <td>00249.5f45607c1bffe89f60ba1ec9f878039a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ATTENTION: This is a MUST for ALL Computer Use...</td>\n",
       "      <td>00373.ebe8670ac56b04125c25100a36ab0510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a multi-part message in MIME format.\\n...</td>\n",
       "      <td>00214.1367039e50dc6b7adb0f2aa8aba83216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...</td>\n",
       "      <td>00210.050ffd105bd4e006771ee63cabc59978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the bottom line.  If you can GIVE AWAY...</td>\n",
       "      <td>00033.9babb58d9298daa2963d4f514193d7d6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm one of the 30,000 but it's not working ver...</td>\n",
       "      <td>00609.dd49926ce94a1ea328cce9b62825bc97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>0</td>\n",
       "      <td>Damien Morton quoted:\\n\\n&gt;W3C approves HTML 4 ...</td>\n",
       "      <td>00957.e0b56b117f3ec5f85e432a9d2a47801f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>0</td>\n",
       "      <td>On Mon, 2002-07-22 at 06:50, che wrote:\\n\\n\\n\\...</td>\n",
       "      <td>01127.841233b48eceb74a825417d8d918abf8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>0</td>\n",
       "      <td>Once upon a time, Manfred wrote :\\n\\n\\n\\n&gt; I w...</td>\n",
       "      <td>01178.5c977dff972cd6eef64d4173b90307f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>0</td>\n",
       "      <td>If you run Pick, and then use the \"New FTOC\" b...</td>\n",
       "      <td>00747.352d424267d36975a7b40b85ffd0885e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5796 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CATEGORY                                            MESSAGE  \\\n",
       "0            1  Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...   \n",
       "1            1  ATTENTION: This is a MUST for ALL Computer Use...   \n",
       "2            1  This is a multi-part message in MIME format.\\n...   \n",
       "3            1  IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...   \n",
       "4            1  This is the bottom line.  If you can GIVE AWAY...   \n",
       "...        ...                                                ...   \n",
       "5791         0  I'm one of the 30,000 but it's not working ver...   \n",
       "5792         0  Damien Morton quoted:\\n\\n>W3C approves HTML 4 ...   \n",
       "5793         0  On Mon, 2002-07-22 at 06:50, che wrote:\\n\\n\\n\\...   \n",
       "5794         0  Once upon a time, Manfred wrote :\\n\\n\\n\\n> I w...   \n",
       "5795         0  If you run Pick, and then use the \"New FTOC\" b...   \n",
       "\n",
       "                                   FILE_NAME  \n",
       "0     00249.5f45607c1bffe89f60ba1ec9f878039a  \n",
       "1     00373.ebe8670ac56b04125c25100a36ab0510  \n",
       "2     00214.1367039e50dc6b7adb0f2aa8aba83216  \n",
       "3     00210.050ffd105bd4e006771ee63cabc59978  \n",
       "4     00033.9babb58d9298daa2963d4f514193d7d6  \n",
       "...                                      ...  \n",
       "5791  00609.dd49926ce94a1ea328cce9b62825bc97  \n",
       "5792  00957.e0b56b117f3ec5f85e432a9d2a47801f  \n",
       "5793  01127.841233b48eceb74a825417d8d918abf8  \n",
       "5794  01178.5c977dff972cd6eef64d4173b90307f0  \n",
       "5795  00747.352d424267d36975a7b40b85ffd0885e  \n",
       "\n",
       "[5796 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/Spam Email raw text for NLP.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c654d464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5796 entries, 0 to 5795\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   CATEGORY   5796 non-null   int64 \n",
      " 1   MESSAGE    5796 non-null   object\n",
      " 2   FILE_NAME  5796 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 136.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#info of data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a301d6",
   "metadata": {},
   "source": [
    "Le dataset ne possède pas de valeurs manquantes ou abberrantes.  \n",
    "La colonne CATEGORY est notre target.  \n",
    "La colonne MESSAGE comporte les mots, phrases et caractères des mails.  \n",
    "FILE_NAME est une colonne que nous allons supprimer pendant le preprossing n'étant pas utile pour notre travail.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7954f6",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c5f54",
   "metadata": {},
   "source": [
    "On commence par faire des séquences avec la tokenisation.  \n",
    "On détermine la taille max des séquences, c'est à dire le nombre de mots maximum par lignes du dataset.  \n",
    "Le **tokenizer** consiste à attribuer des nombres pour chaque mot repéré. Afin de ne pas avoir de problème de *shape*, il va normaliser la taille des phrases avec des **0**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3bbaff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(texts, tokenizer, train=True, max_seq_length=None):\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    if train == True:\n",
    "        max_seq_length = np.max(list(map(lambda x: len(x), sequences)))\n",
    "    \n",
    "    sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaae289",
   "metadata": {},
   "source": [
    "Dans le code suivant, nous déterminons X et Y pour notre modèle tokenizer et supprimons \"FILE NAME\".  \n",
    "On effectue ensuite un train_test_split, pour diviser notre dataset. Le train va servir d'entrainement au modèle et fait la taille de **0.7** (**soit 70% de la donnée**). Il lui reste donc **30% de test**.  \n",
    "On fit ensuite notre tokenizer pour qu'il créée son dictionnaire.  \n",
    "Le tokenizer est sauvegardé sous le format pickle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c687269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop FILE_NAME column\n",
    "    df = df.drop('FILE_NAME', axis=1)\n",
    "    \n",
    "    # Split df into X and y\n",
    "    y = df['CATEGORY']\n",
    "    X = df['MESSAGE']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n",
    "    \n",
    "    # Create tokenizer\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=30000)\n",
    "    \n",
    "    # Fit the tokenizer\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "    # Convert texts to sequences\n",
    "    X_train = get_sequences(X_train, tokenizer, train=True)\n",
    "    X_test = get_sequences(X_test, tokenizer, train=False, max_seq_length=X_train.shape[1])\n",
    "    \n",
    "    #save token\n",
    "    with open('tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c348a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_inputs(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af4037f",
   "metadata": {},
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88ba6341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data[\"MESSAGE\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bd9ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=30000)\n",
    "# tokenizer.fit_on_texts(data[\"MESSAGE\"])\n",
    "# seq = tokenizer.texts_to_sequences(data[\"MESSAGE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ab1fee4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# max_len = 0\n",
    "# for i in data[\"MESSAGE\"]:\n",
    "#     seq = tokenizer.texts_to_sequences(i)\n",
    "#     tmp_len = len(seq)\n",
    "#     if tmp_len > max_len:\n",
    "#         max_len = tmp_len\n",
    "#         max_phrase = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97a0f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6430963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len = np.max(list(map(lambda x : len(x),seq)))\n",
    "# sequences = tf.keras.preprocessing.sequence.pad_sequences(seq, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e86a9b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a754ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = preprocess_inputs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ea0874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e165a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3234f122",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c465bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4057, 14804)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c06d346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 14804)]           0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 14804, 64)         1920000   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 947456)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 947457    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,867,457\n",
      "Trainable params: 2,867,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(14804,))\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=30000,\n",
    "    output_dim=64\n",
    ")(inputs)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(embedding)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(flatten)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "#compile\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70dfa5ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 21s 196ms/step - loss: 0.5848 - accuracy: 0.8361 - auc: 0.8366 - val_loss: 0.0970 - val_accuracy: 0.9766 - val_auc: 0.9974\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 21s 202ms/step - loss: 0.0485 - accuracy: 0.9892 - auc: 0.9995 - val_loss: 0.0407 - val_accuracy: 0.9877 - val_auc: 0.9990\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 18s 177ms/step - loss: 0.0143 - accuracy: 0.9972 - auc: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9889 - val_auc: 0.9991\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 18s 176ms/step - loss: 0.0070 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9889 - val_auc: 0.9992\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 18s 176ms/step - loss: 0.0045 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9889 - val_auc: 0.9991\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 19s 190ms/step - loss: 0.0031 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9889 - val_auc: 0.9991\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 18s 180ms/step - loss: 0.0024 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9901 - val_auc: 0.9974\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 18s 177ms/step - loss: 0.0018 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9901 - val_auc: 0.9974\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 19s 183ms/step - loss: 0.0015 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9914 - val_auc: 0.9975\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a119c12",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8187030d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Loss: 0.0229\n",
      "Test Accuracy: 99.19%\n",
      "     Test AUC: 0.9989\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.4f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))\n",
    "print(\"     Test AUC: {:.4f}\".format(results[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c07c9c",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "754903a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "# ##### SAVE MODEL JUST ONE TIME #####\n",
    "save_model(model,'model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f674a",
   "metadata": {},
   "source": [
    "## Code refactored for application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28284383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, render_template, request\n",
    "# import pandas as pd\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras import layers, Model, metrics, callbacks\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# @app.route('/')\n",
    "# def home():\n",
    "#     return render_template('index.html')\n",
    "\n",
    "# @app.route('/predict', methods=['POST'])\n",
    "# def predict():\n",
    "\n",
    "#     def get_sequences(texts, tokenizer, train=True, max_seq_length=None):\n",
    "#         sequences = tokenizer.texts_to_sequences(texts)    \n",
    "#     if train == True:\n",
    "#         max_seq_length = np.max(list(map(lambda x: len(x), sequences)))        \n",
    "#     sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "#     return sequences\n",
    "\n",
    "#     def preprocess_test(df):\n",
    "#         df = df.copy()\n",
    "    \n",
    "#         # Drop FILE_NAME column\n",
    "#         df = df.drop('FILE_NAME', axis=1)\n",
    "    \n",
    "#         # Split df into X and y\n",
    "#         y = df['CATEGORY']\n",
    "#         X = df['MESSAGE']\n",
    "   \n",
    "#         # Create tokenizer\n",
    "#         tokenizer = pickle.load(open(\"tokenizer.pickle\",\"rb\"))\n",
    "#         X_train_len = 14804\n",
    "    \n",
    "#         # Convert texts to sequences\n",
    "#         X_test = get_sequences(X, tokenizer, train=False, max_seq_length=X_train_len)\n",
    "#         return X_test, y\n",
    "\n",
    "#         model = load_model('model.h5')\n",
    "\n",
    "#         if request.method == 'POST':\n",
    "#             message = request.form['message']\n",
    "#             data = [message]\n",
    "#             my_prediction = model.predict(X_test)\n",
    "#         return render_template('index.html', prediction=my_prediction)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd879be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
