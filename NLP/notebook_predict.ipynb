{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d98ed4c",
   "metadata": {},
   "source": [
    "## Introduction du notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a06cada",
   "metadata": {},
   "source": [
    "Nous sommes plusieurs petites équipes de Développeurs en IA, avec plusieurs projets proposés par notre instructeur !    \n",
    "\n",
    "\n",
    "Notre équipe est chargée de créer un model IA capable de détecter les SPAM dans les Email, qu'elle puisse différencier ceux qui le sont avec ceux qui ne le sont pas, grâce à la méthode du NLP (Natural Langage processing)  \n",
    "\n",
    "Le **NLP** est une technologie d’intelligence artificielle visant à permettre aux ordinateurs de comprendre le langage humain.\n",
    "L’objectif de cette technologie est de permettre aux machines de lire, de déchiffrer, de comprendre et de donner sens au langage humain.  \n",
    "\n",
    "Nous allons vous montrer une modèle qui possède une couche d'**Embedding**. Il s'agit d'un espace dit \"peu dimensionnel\" dans lequel nous pouvon traduire traduire des vecteurs à haute dimension. Cela facilite l'apprentissage automatique de notre IA sur des entrées de grande taille. L'avantage de ce modèle est qu'il pourra apprendre et être réutilisé dans plusieurs modèles (donc sur d'autres jeux de données).  \n",
    "\n",
    "Pour notre projet nous avons à notre disposition une base de données comportant des mails, classé par 1 ou 0.\n",
    "* 0 sont les mail non-spam.  \n",
    "* 1 sont les mail considérés comme des spam.  \n",
    "\n",
    "Dans ce notebook protocole/predict, vous pourrez suivre les étapes (Step by steps) pour pouvoir utiliser notre modèle avec différentes données.\n",
    "\n",
    "Allons-y !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c2804",
   "metadata": {},
   "source": [
    "## Explication step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dbadc0",
   "metadata": {},
   "source": [
    "### Import the libraries that are recquired for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "338031d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### FIRST CELL TO EXECUTE : Importing libraries ######\n",
    "\n",
    "# Basic imports\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "#loading\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89393ba",
   "metadata": {},
   "source": [
    "### Import pickle, model and your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac5345ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SECOND CELL TO EXECUTE : Importing data that you wan to test ######\n",
    "\n",
    "# Here, you need to replace the string 'PATHNAME_OF_YOUR_DATA_FILE' by the pathname of your file\n",
    "# For example : model_df = pd.read_csv('data/eda_clean_df.csv')\n",
    "# model_df = pd.read_csv('PATHNAME_OF_YOUR_DATA_FILE')\n",
    "\n",
    "df = pd.read_csv('data/Spam Email raw text for NLP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c10bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you need Importing our trained model\n",
    "# Here, you need to use the file \"model.h5\" that you will find here :\n",
    "# https://github.com/Melodyellinn/Projet_NLP\n",
    "\n",
    "model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13331338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### Run this function for creat sequences ##### #\n",
    "\n",
    "def get_sequences(texts, tokenizer, train=True, max_seq_length=None):\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    if train == True:\n",
    "        max_seq_length = np.max(list(map(lambda x: len(x), sequences)))\n",
    "    \n",
    "    sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a78fe954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### Here, execute this cell for apply the presprocessing steps to clean data and creat the tokeniser for model. ##### #\n",
    "\n",
    "# secure df\n",
    "df = df.copy()\n",
    "\n",
    "# Drop FILE_NAME column\n",
    "df = df.drop('FILE_NAME', axis=1)\n",
    "# Split df into X and y\n",
    "y = df['CATEGORY']\n",
    "X = df['MESSAGE']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n",
    "# Create tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=30000)\n",
    "# Fit the tokenizer\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert texts to sequences\n",
    "X_train = get_sequences(X_train, tokenizer, train=True)\n",
    "X_test = get_sequences(X_test, tokenizer, train=False, max_seq_length=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "420bf6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### Execute this cell for use the model.evaluate your dataset with the IA model ##### #\n",
    "results = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07ac7921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Loss: 0.0229\n",
      "Test Accuracy: 99.19%\n",
      "     Test AUC: 0.9989\n"
     ]
    }
   ],
   "source": [
    "# ##### Print the results ! ##### #\n",
    "print(\"    Test Loss: {:.4f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))\n",
    "print(\"     Test AUC: {:.4f}\".format(results[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2089ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99998450e-01]\n",
      " [9.99937773e-01]\n",
      " [1.11707945e-04]\n",
      " ...\n",
      " [5.95420599e-04]\n",
      " [2.11740758e-06]\n",
      " [9.98863399e-01]]\n"
     ]
    }
   ],
   "source": [
    "# ##### result's predictions ##### #\n",
    "my_prediction = model.predict(X_test)\n",
    "print(my_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fe3827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
